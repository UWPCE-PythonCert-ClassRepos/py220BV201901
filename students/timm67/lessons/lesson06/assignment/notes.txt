The main change that I made was changing the two context manager CSV file processing
steps into one. 

Because of the size of the CSV file, I put it into a zip archive, so the script 
spends 1.5 seconds at the beginning to decompress the CSV file. I found that this
single change along with changing the else: clauses into elif: clauses so that the
if-elif conditional drops out as soon as the desired value is found, made a significant
difference. 

Below is an example run:

Poor performance...

D-10-156-31-182:assignment timm$ python3 poor_perf.py 
Extracting [./dataexercise-new.csv] from [./data/data.zip]
{'2013': 5911, '2014': 5854, '2015': 5994, '2016': 5762, '2017': 11600, '2018': 0}
'ao' was found 63395 times
start[1.572067682] end[9.072224619]
ao found [63395] times

Better performance...

D-10-156-31-182:assignment timm$ python3 good_perf.py 
Extracting [./dataexercise-new.csv] from [./data/data.zip]
{'2013': 5911, '2014': 5854, '2015': 5994, '2016': 5762, '2017': 11600, '2018': 0}
start[1.551224486] end[5.974014123]
ao found [63395] times

The difference between the two times was 3 seconds or roughly 30 percent improvement. 

Run the ./do_compare.sh file to reproduce the results. 